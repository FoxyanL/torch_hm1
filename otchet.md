# Отчет по домашнему заданию: Основы PyTorch

## Задание 1: Работа с тензорами (25 баллов)

### 1.1 Создание тензоров (7 баллов)
- Тензор 3x4 с случайными значениями от 0 до 1 (`torch.rand`)
- Тензор 2x3x4, заполненный нулями (`torch.zeros`)
- Тензор 5x5, заполненный единицами (`torch.ones`)
- Тензор 4x4 с числами от 0 до 15, используя `reshape` и `torch.arange`

### 1.2 Операции с тензорами (6 баллов)
- Транспонирование тензора `A` (`A.T`)
- Матричное умножение `A @ B`
- Поэлементное умножение `A * B.T`
- Сумма всех элементов `A.sum()`

### 1.3 Индексация и срезы (6 баллов)
- Первая строка: `tensor[0]`
- Последний столбец: `tensor[:, -1]`
- Центр 2x2: `tensor[2:4, 2:4]`
- Четные индексы: `tensor[::2, ::2, ::2]`

### 1.4 Работа с формами (6 баллов)
- `reshape` в формы:
  - 2x12
  - 3x8
  - 4x6
  - 2x3x4
  - 2x2x2x3


## Задание 2: Автоматическое дифференцирование (25 баллов)

### 2.1 Градиенты функции f(x,y,z) (8 баллов)
- `f = x² + y² + z² + 2xyz`
- Градиенты по x, y, z через `backward()`
- Проверена аналитическая формула

### 2.2 MSE и градиенты (9 баллов)
- Реализация `MSE = ((y_pred - y_true)**2).mean()`
- `y_pred = wx + b`
- Градиенты по `w` и `b`

### 2.3 Цепное правило (8 баллов)
- `f(x) = sin(x² + 1)`
- Градиент `df/dx` через `backward` и `torch.autograd.grad`
- Проверка правильности


## Задание 3: CPU vs CUDA (20 баллов)

### 3.1 Подготовка данных (5 баллов)
- Матрицы:
  - 64x1024x1024
  - 128x512x512
  - 256x256x256

### 3.2 Функция измерения времени (5 баллов)
- `time.time()` для CPU
- `torch.cuda.Event()` для GPU
- Автоматический выбор устройства

### 3.3 Сравнение операций (10 баллов)
- Результаты:
| Операция           | Размер         | CPU (мс) | GPU (мс) | Ускорение |
|--------------------|----------------|----------|----------|-----------|
| Мат. умножение     | 64x1024x1024   | 380.94   | 140.96   | 2.7x      |
| Сложение           | 64x1024x1024   | 19.24    | 14.84    | 1.3x      |
| Умножение          | 64x1024x1024   | 18.51    | 8.16     | 2.27x     |
| Транспонирование   | 64x1024x1024   | 0.00     | 0.05     | 0.0x      |
| Суммирование       | 64x1024x1024   | 9.21     | 8.79     | 1.05x     |
| Мат. умножение     | 128x512x512    | 76.39    | 4.33     | 17.64x    |
| Сложение           | 128x512x512    | 9.21     | 1.98     | 4.66x     |
| Умножение          | 128x512x512    | 9.63     | 1.81     | 5.33x     |
| Транспонирование   | 128x512x512    | 0.00     | 0.04     | 0.0x      |
| Суммирование       | 128x512x512    | 6.47     | 0.75     | 8.62x     |
| Мат. умножение     | 256x256x256    | 22.03    | 1.34     | 16.48x    |
| Сложение           | 256x256x256    | 6.01     | 0.96     | 6.26x     |
| Умножение          | 256x256x256    | 5.02     | 0.98     | 5.11x     |
| Транспонирование   | 256x256x256    | 1.00     | 0.04     | 22.65x    |
| Суммирование       | 256x256x256    | 1.52     | 0.48     | 3.19x     |

### 3.4 Анализ (5 баллов)
- Наибольшее ускорение получили:
  - матричное умножение (до ~17.6x),
  - транспонирование и суммирование при больших размерах.

- GPU может быть медленнее, если:
  - размер данных слишком мал (накладные расходы выше выгоды от параллелизации),
  - есть частые переходы между CPU и GPU.

- Чем больше размер матрицы, тем выше ускорение — большие данные лучше загружают параллельные ядра GPU.

- Передача между CPU и GPU занимает время, поэтому её следует минимизировать, особенно в циклах.


